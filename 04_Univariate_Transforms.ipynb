{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def prepFeatures(X):\n",
    "    \"Apply z-score normalization to nxd feature matrix\"\n",
    "    ss = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xz = ss.fit_transform(X)\n",
    "    return Xz,ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def trainOOBClassifier(X,y, modelFactory=lambda: DecisionTreeClassifier(),n_estimators=100):\n",
    "    \"\"\"\n",
    "    Train ensemble of <n_estimators> models predicting the probability that each\n",
    "    instance came from the labeled positive, rather than the unlabeled mixture, set.\n",
    "    \n",
    "    Required Arguments:\n",
    "        - X : ndarray shape (n,d) : feature matrix\n",
    "        - y : ndarray shape (n,)  : positive v. unlabeled component assignments for each instance\n",
    "    Optional Arguments:\n",
    "        - modelFactory : lambda function returning sklearn-style model instance (has fit, fit_predict, predict_proba, ... functions) : default DicisionTreeRegressor\n",
    "        - n_estimators : size of the ensemble : default 100\n",
    "        \n",
    "    Returns\n",
    "        - transform_scores : ndarray (n,) : probability that each instance came from labeled positive set, calculating using out-of-bag scores\n",
    "        - auc_pu : float : the AUROC of this non-traditional classifier\n",
    "    \"\"\"\n",
    "    # z-score normalization is applied to the whole dataset prior to training\n",
    "    X,ss = prepFeatures(X)\n",
    "    clf = BaggingClassifier(n_jobs=-1,base_estimator=modelFactory(), n_estimators=n_estimators,\n",
    "                            max_samples=X.shape[0],max_features=X.shape[1], bootstrap=True,\n",
    "                            bootstrap_features=False, oob_score=True).fit(X,y)\n",
    "    transform_scores = clf.oob_decision_function_[:,1]\n",
    "    auc_pu = roc_auc_score(y, transform_scores)\n",
    "    return transform_scores, auc_pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def trainKFoldClassifier(X,y, modelFactory=lambda: SVC(probability=True, degree=1),KFoldValue=10):\n",
    "    \"\"\"\n",
    "    Train model using K-fold cross-validation\n",
    "    Required Arguments:\n",
    "        - X : ndarray shape (n,d) : feature matrix\n",
    "        - y : ndarray shape (n,)  : positive v. unlabeled component assignments for each instance\n",
    "    Optional Arguments:\n",
    "        - modelFactory : lambda function returning sklearn-style model instance (has fit, fit_predict, predict_proba, ... functions) : default SVC\n",
    "        - KFoldValue : number of folds to use in k-fold cross-validation : default 10\n",
    "        \n",
    "    Returns\n",
    "        - transform_scores : ndarray (n,) : probability that each instance came from labeled positive set\n",
    "        - auc_pu : float : the AUROC of this non-traditional classifier\n",
    "\n",
    "    \"\"\"\n",
    "    transform_scores = np.zeros(y.shape, dtype=float)\n",
    "    # z-score normalization applied globally rather than within each k-fold iteration\n",
    "    X,ss = prepFeatures(X)\n",
    "    kf = KFold(n_splits=KFoldValue, shuffle=False)\n",
    "    for train_indices, val_indices in kf.split(X):\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_val = X[val_indices]\n",
    "        clf = modelFactory()\n",
    "        clf.fit(X_train, y_train)\n",
    "        transform_scores[val_indices] = clf.predict_proba(X_val)[:,1]\n",
    "    auc_pu = roc_auc_score(y, transform_scores)\n",
    "    return transform_scores, auc_pu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test k-fold and oob transform functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from sklearn.datasets import load_wine\n",
    "X,y = load_wine(return_X_y=True)\n",
    "y = y == 1\n",
    "\n",
    "transform_scores, auc_pu = trainOOBClassifier(X,y,modelFactory=lambda: DecisionTreeClassifier())\n",
    "\n",
    "auc_pu\n",
    "\n",
    "transform_scores, auc_pu = trainKFoldClassifier(X,y)\n",
    "\n",
    "auc_pu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def getOptimalTransform(X,y):\n",
    "    \"\"\"\n",
    "    Train the 6 univariate transforms from (Zeiberg 2020) and return the transform scores and auc_pu for the best transform\n",
    "    \n",
    "    Required Arguments:\n",
    "        - X : ndarray shape (n,d) : feature matrix\n",
    "        - y : ndarray shape (n,)  : positive v. unlabeled component assignments for each instance\n",
    "    Returns:\n",
    "        - transform_scores : ndarray (n,) : probability that each instance came from labeled positive set\n",
    "        - auc_pu : float : the AUROC of this non-traditional classifier\n",
    "    \"\"\"\n",
    "    transform_scores, auc_pu = {},{}\n",
    "    models = [(\"nn_1\",lambda: MLPClassifier(hidden_layer_sizes=(1,1)), 100),\n",
    "              (\"nn_5\",lambda: MLPClassifier(hidden_layer_sizes=(1,1)), 100),\n",
    "              (\"nn_25\",lambda: MLPClassifier(hidden_layer_sizes=(1,1)), 100),\n",
    "              (\"rt\",lambda: DecisionTreeClassifier(), 1000),\n",
    "              (\"svm_1\",lambda: SVC(kernel=\"poly\", degree=1, probability=True),10),\n",
    "              (\"svm_2\",lambda: SVC(kernel=\"poly\", degree=1, probability=True),10)]\n",
    "    for model_name, model_factory, n in tqdm(models,total=len(models),desc=\"Training univariate transforms\"):\n",
    "        if \"svm\" in model_name:\n",
    "            scores, auc = trainKFoldClassifier(X,y,modelFactory=model_factory,KFoldValue=n)\n",
    "        else:\n",
    "            scores, auc = trainOOBClassifier(X,y,modelFactory=model_factory, n_estimators=n)\n",
    "        transform_scores[model_name] = scores\n",
    "        auc_pu[model_name] = auc\n",
    "    # Find the best transform\n",
    "    best_auc = .5\n",
    "    best_transform = \"rt\"\n",
    "    for model_name, auc in auc_pu.items():\n",
    "        if auc > best_auc:\n",
    "            best_transform = model_name\n",
    "            best_auc = auc\n",
    "    return transform_scores[best_transform], auc_pu[best_transform]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7380f35c9ab042a7a889ab806b516ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training univariate transforms', max=6.0, style=ProgressSâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.07515643e-03, 3.60473235e-02, 6.55373493e-03, 3.83785950e-06,\n",
       "        6.81979083e-02, 4.70577594e-05, 1.19391382e-04, 1.58549760e-04,\n",
       "        1.32628179e-03, 2.12317286e-03, 1.04722689e-03, 2.00573312e-03,\n",
       "        1.68003911e-03, 1.31197355e-03, 2.51206510e-05, 2.58612120e-04,\n",
       "        1.08824953e-04, 2.55565139e-03, 1.02574625e-04, 7.49275296e-03,\n",
       "        7.27393431e-02, 1.44502935e-01, 2.40942095e-01, 4.77789304e-01,\n",
       "        5.75741165e-01, 4.47679771e-01, 1.06029002e-02, 9.60032412e-02,\n",
       "        1.35980309e-01, 6.18680163e-02, 3.53915213e-02, 2.94314925e-03,\n",
       "        4.16966501e-01, 1.76887103e-02, 6.16097460e-02, 2.39477871e-01,\n",
       "        8.50807299e-03, 5.20566248e-02, 6.77669266e-01, 4.63120650e-04,\n",
       "        8.98054684e-02, 6.54562839e-02, 6.33869719e-04, 1.29062791e-01,\n",
       "        4.72159644e-01, 2.15235928e-04, 3.48517071e-03, 2.66736987e-02,\n",
       "        5.75185414e-03, 7.15878198e-04, 7.19519092e-02, 2.60933711e-03,\n",
       "        9.66662216e-04, 1.56537969e-04, 1.86453116e-03, 5.84415829e-03,\n",
       "        7.38493729e-04, 2.70070073e-04, 1.15685543e-04, 9.86995007e-01,\n",
       "        4.66698295e-01, 3.59493755e-01, 4.56315916e-01, 9.96064073e-01,\n",
       "        9.87942634e-01, 7.74042555e-01, 9.86911811e-01, 9.94395359e-01,\n",
       "        1.85081937e-02, 9.99997114e-01, 8.23539753e-01, 9.09365339e-01,\n",
       "        8.61743334e-01, 8.53524008e-01, 9.26222309e-01, 9.99999833e-01,\n",
       "        9.97268444e-01, 9.92278667e-01, 9.91243487e-01, 9.95392222e-01,\n",
       "        1.00000000e+00, 9.56332242e-01, 9.99998984e-01, 4.85286835e-01,\n",
       "        9.84347400e-01, 9.99993400e-01, 9.99999928e-01, 9.99999871e-01,\n",
       "        9.94106294e-01, 9.99998032e-01, 9.99993335e-01, 9.97230064e-01,\n",
       "        9.91494668e-01, 9.99999483e-01, 9.99999469e-01, 9.09058847e-01,\n",
       "        5.92692817e-01, 9.99999927e-01, 9.97276859e-01, 9.99999995e-01,\n",
       "        9.99999330e-01, 9.96901041e-01, 9.55845190e-01, 9.99999981e-01,\n",
       "        9.96503422e-01, 9.99982483e-01, 9.97260924e-01, 9.83370204e-01,\n",
       "        9.99998978e-01, 9.87264321e-01, 9.99984342e-01, 9.95252638e-01,\n",
       "        8.65152165e-01, 9.99999376e-01, 9.95630845e-01, 1.00000000e+00,\n",
       "        9.99999723e-01, 9.99998908e-01, 6.16024625e-01, 9.96935950e-01,\n",
       "        9.70941144e-01, 8.39139399e-01, 9.45720154e-01, 5.74962837e-01,\n",
       "        9.72352640e-01, 9.96940035e-01, 9.85313557e-01, 9.99996313e-01,\n",
       "        9.99999401e-01, 9.42126016e-01, 5.57764271e-01, 2.35039582e-01,\n",
       "        4.63564789e-01, 3.66384837e-01, 4.60544954e-01, 1.00181127e-01,\n",
       "        2.33205043e-01, 2.67603393e-01, 6.52887944e-02, 3.56212472e-01,\n",
       "        8.38589847e-02, 1.22411234e-02, 1.26070100e-01, 5.45951422e-02,\n",
       "        1.71943008e-03, 2.19033806e-02, 2.43776137e-03, 6.98161065e-04,\n",
       "        5.71522692e-04, 4.61951562e-04, 2.87720742e-04, 3.43025768e-04,\n",
       "        1.11136848e-02, 1.81628306e-04, 9.08828678e-02, 7.12219940e-04,\n",
       "        1.35933309e-04, 8.79587756e-03, 7.59159560e-06, 1.18091314e-04,\n",
       "        1.97341809e-02, 3.05627019e-03, 7.51311816e-02, 9.42816109e-03,\n",
       "        3.27891898e-04, 7.42183598e-03, 7.00879023e-05, 4.63785486e-04,\n",
       "        2.30212981e-04, 5.06267001e-05, 1.86115821e-01, 2.36598966e-03,\n",
       "        1.54524094e-05, 2.72527573e-05, 6.16950180e-04, 1.90607076e-05,\n",
       "        1.23089770e-04, 1.70816128e-05]),\n",
       " 0.9907858365144135)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "getOptimalTransform(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
