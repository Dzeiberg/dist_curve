{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "\n",
    "from scipy.io import loadmat,savemat\n",
    "import h5py\n",
    "from easydict import EasyDict\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from dist_curve.transforms import getOptimalTransform\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.sched_setaffinity(0,set(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFile(dsPath):\n",
    "    try:\n",
    "        ds = loadmat(dsPath)\n",
    "    except:\n",
    "        ds= {}\n",
    "        for k,v in h5py.File(dsPath,\"r\").items():\n",
    "            ds[k] = np.array(v)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPUDatasetInstance(data):\n",
    "    # get indices of all positives and negatives\n",
    "    posIdxs = np.where(data.y == 1)[0]\n",
    "    negIdxs = np.where(data.y == 0)[0]\n",
    "    if len(posIdxs) < 1000:\n",
    "        numPos = 100\n",
    "    else:\n",
    "        numPos = 1000\n",
    "    # Split Positive data into component and mixture\n",
    "    numUnlabeledPos = len(posIdxs) - numPos\n",
    "    unlabeledPosIdxs = np.random.choice(posIdxs,\n",
    "                                     replace=False,size=numUnlabeledPos)\n",
    "    posComponentIdxs = list(set(posIdxs) - set(unlabeledPosIdxs))\n",
    "    posInstances = data.X[posComponentIdxs]\n",
    "    # Downsample mixture if necessary\n",
    "    if len(negIdxs) + len(unlabeledPosIdxs) > 10000:\n",
    "        n0 = int(10000 * len(negIdxs)/(len(negIdxs) + len(unlabeledPosIdxs)))\n",
    "        n1 = 10000 - n0\n",
    "        unlabeledNegIdxs = np.random.choice(negIdxs, replace=False,size=n0)\n",
    "        unlabeledPosIdxs = np.random.choice(unlabeledPosIdxs,replace=False,size=n1)\n",
    "    else:\n",
    "        unlabeledNegIdxs = negIdxs\n",
    "    unlabeledInstances = data.X[np.concatenate((unlabeledPosIdxs, unlabeledNegIdxs))]\n",
    "    \n",
    "    hiddenLabels = np.concatenate((np.ones_like(unlabeledPosIdxs),\n",
    "                                   np.zeros_like(unlabeledNegIdxs)))\n",
    "    \n",
    "    pu_instance = EasyDict({\n",
    "        \"positiveInstances\": posInstances,\n",
    "        \"unlabeledInstances\": unlabeledInstances,\n",
    "        \"hiddenLabels\": hiddenLabels,\n",
    "        \"alpha\": hiddenLabels.sum()/len(hiddenLabels)})\n",
    "    return pu_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addOptimalTransformToInstance(inst):\n",
    "    p = inst.positiveInstances\n",
    "    u = inst.unlabeledInstances\n",
    "    x = np.concatenate((p,u))\n",
    "    s = np.concatenate((np.ones(p.shape[0]),\n",
    "                        np.zeros(u.shape[0])))\n",
    "    probs, aucPU = getOptimalTransform(x,s)\n",
    "    posScores = probs[:p.shape[0]]\n",
    "    unlabeledScores = probs[p.shape[0] + 1:]\n",
    "    out = EasyDict(inst)\n",
    "    out.posScores = posScores\n",
    "    out.unlabeledScores = unlabeledScores\n",
    "    out.aucPU = aucPU\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob(\"/data/dzeiberg/ClassPriorEstimation/rawDatasets/*.mat\")\n",
    "for filename in tqdm(filenames,total=len(filenames),leave=False):\n",
    "    dsname = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    if not os.path.isfile(\"/data/dzeiberg/ClassPriorEstimation/processedDatasets/{}.pkl\".format(dsname)):\n",
    "        ds = EasyDict(getFile(filename))\n",
    "        ds.instances = []\n",
    "        NInstances = 10\n",
    "        for inst_num in tqdm(range(NInstances),total=NInstances,leave=False):\n",
    "            inst = getPUDatasetInstance(ds)\n",
    "            ds.instances.append(addOptimalTransformToInstance(inst))\n",
    "            pickle.dump(ds,open(\"/data/dzeiberg/ClassPriorEstimation/processedDatasets/{}.pkl\".format(dsname),\"wb\"))\n",
    "            savemat(\"/data/dzeiberg/ClassPriorEstimation/processedDatasets/{}.mat\".format(dsname),ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = EasyDict(pickle.load(open(\"/data/dzeiberg/ClassPriorEstimation/processedDatasets_partial/abalone.pkl\",\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.instances[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
